#!/usr/bin/env python3
"""
LogWise - AI-Powered Log Analysis & RCA Assistant
Simplified function-based version for learning
"""

import argparse
import json
import sys
import os
import subprocess
from datetime import datetime
from typing import Dict
import requests


def check_connection(ollama_url: str) -> bool:
    """Check if Ollama is running and accessible"""
    try:
        response = requests.get(f"{ollama_url}/api/tags", timeout=5)
        return response.status_code == 200
    except requests.RequestException:
        return False


def ensure_model(ollama_url: str, model: str) -> bool:
    """Ensure the required model is available"""
    try:
        response = requests.get(f"{ollama_url}/api/tags")
        if response.status_code == 200:
            models = response.json().get('models', [])
            for m in models:
                if m.get('name') == model:
                    return True

        # Try to pull the model if not available
        print(f"Model {model} not found. Attempting to pull...")
        result = subprocess.run(['ollama', 'pull', model],
                                capture_output=True, text=True)
        return result.returncode == 0
    except Exception as e:
        print(f"Error checking model availability: {e}")
        return False


def preprocess(content: str) -> str:
    """Preprocess log content to extract relevant information"""
    lines = content.strip().split('\n')

    # Filter out empty lines and extremely long lines
    filtered_lines = [line.strip() for line in lines if line.strip() and len(line) < 1000]

    # If too many lines, take a sample
    if len(filtered_lines) > 200:
        filtered_lines = filtered_lines[:100] + ["... (truncated) ..."] + filtered_lines[-100:]

    return '\n'.join(filtered_lines)


def analyze_logs(log_content: str, ollama_url: str, model: str) -> Dict:
    """Analyze log content using AI model"""
    if not check_connection(ollama_url):
        return {"error": "Cannot connect to Ollama. Ensure it is running."}

    if not ensure_model(ollama_url, model):
        return {"error": f"Model {model} is not available."}

    preprocessed = preprocess(log_content)

    prompt = f"""
You are an expert in troubleshooting and root cause analysis across IT systems, applications, and infrastructure.
Analyze the following log entries and provide a clear, human-readable report.

## SUMMARY
High-level overview of what is happening

## ISSUES IDENTIFIED
List of key errors, warnings, or anomalies

## SEVERITY ASSESSMENT
- Critical: Immediate attention needed
- Warning: Monitor closely
- Info: Normal or minor events

## ROOT CAUSE HYPOTHESIS
Possible reasons for the issues

## RECOMMENDATIONS
Specific next steps for troubleshooting or fixing the issues

## PATTERNS OBSERVED
Any repeating errors, timestamps, or correlations

Here are the logs:

{preprocessed}
"""

    try:
        response = requests.post(
            f"{ollama_url}/api/generate",
            json={"model": model, "prompt": prompt, "stream": False},
            timeout=300
        )

        if response.status_code == 200:
            result = response.json()
            return {
                "success": True,
                "analysis": result.get("response", "No response generated"),
                "timestamp": datetime.now().isoformat()
            }
        else:
            return {"error": f"API request failed with status {response.status_code}"}

    except requests.RequestException as e:
        return {"error": f"Request failed: {str(e)}"}


def format_output(analysis_result: Dict, format_type: str, model: str) -> str:
    """Format the analysis output"""
    if "error" in analysis_result:
        return f"Error: {analysis_result['error']}"

    if format_type == "json":
        return json.dumps(analysis_result, indent=2)

    # Text format
    output = []
    output.append("LogWise - AI LOG ANALYSIS & RCA REPORT")
    output.append("=" * 60)
    output.append(f"Generated: {analysis_result.get('timestamp', 'Unknown')}")
    output.append("")
    output.append(analysis_result.get('analysis', 'No analysis available'))
    output.append("")
    output.append("=" * 60)
    output.append(f"Generated by LogWise (Model: {model})")

    return "\n".join(output)


def main():
    parser = argparse.ArgumentParser(
        description="LogWise - AI-powered log analysis and troubleshooting assistant",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  %(prog)s -f /var/log/syslog
  %(prog)s -f /var/log/app/error.log --format json
  tail -n 200 app.log | %(prog)s --stdin
  %(prog)s -f system.log -o report.txt --model llama3:8b
        """
    )

    parser.add_argument('-f', '--file', help='Log file to analyze')
    parser.add_argument('--stdin', action='store_true', help='Read log content from stdin')
    parser.add_argument('-o', '--output', help='Output file (default: stdout)')
    parser.add_argument('--format', choices=['text', 'json'], default='text', help='Output format')
    parser.add_argument('--lines', type=int, default=0, help='Number of lines from end of file (0 = all)')
    parser.add_argument('--url', default='http://localhost:11434', help='Ollama API URL')
    parser.add_argument('--model', default='llama3:8b', help='Model to use for analysis')

    args = parser.parse_args()

    if not args.file and not args.stdin:
        parser.error("Must specify either --file or --stdin")
    if args.file and args.stdin:
        parser.error("Cannot specify both --file and --stdin")

    # Read log content
    try:
        if args.stdin:
            log_content = sys.stdin.read()
        else:
            if not os.path.exists(args.file):
                print(f"Error: File '{args.file}' not found", file=sys.stderr)
                sys.exit(1)

            with open(args.file, 'r', encoding='utf-8', errors='ignore') as f:
                if args.lines > 0:
                    lines = f.readlines()
                    log_content = ''.join(lines[-args.lines:])
                else:
                    log_content = f.read()

    except Exception as e:
        print(f"Error reading log content: {e}", file=sys.stderr)
        sys.exit(1)

    if not log_content.strip():
        print("Error: No log content to analyze", file=sys.stderr)
        sys.exit(1)

    # Analyze logs
    print("Analyzing logs with AI...", file=sys.stderr)
    result = analyze_logs(log_content, args.url, args.model)

    # Format and output result
    formatted_output = format_output(result, args.format, args.model)

    if args.output:
        try:
            with open(args.output, 'w', encoding='utf-8') as f:
                f.write(formatted_output)
            print(f"Analysis saved to {args.output}", file=sys.stderr)
        except Exception as e:
            print(f"Error writing output file: {e}", file=sys.stderr)
            sys.exit(1)
    else:
        print(formatted_output)


if __name__ == "__main__":
    main()
